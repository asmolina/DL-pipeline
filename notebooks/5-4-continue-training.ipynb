{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39787a1-9819-4919-9636-7411b54336e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "SCRIPT_DIR = Path('/home/alina.smolina/eolearn-pipeline/src')\n",
    "sys.path.append(str(SCRIPT_DIR))\n",
    "SCRIPT_DIR = Path('/home/alina.smolina/DL-pipeline/src')\n",
    "sys.path.append(str(SCRIPT_DIR))\n",
    "\n",
    "\n",
    "eopatches_dir = '/beegfs/home/alina.smolina/data/sakhalin/images/EOPatches/train_2560_K_N_v2/'\n",
    "num_ids_train = 598\n",
    "\n",
    "\n",
    "eopatches_dir_test = '/beegfs/home/alina.smolina/data/sakhalin/images/EOPatches/test_2560_Nevelsk_v2/'\n",
    "num_ids_test = 44\n",
    "\n",
    "\n",
    "from datamodule_eolearn import GeoEOModule\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch as AP\n",
    "\n",
    "transforms = A.Compose([\n",
    "    A.Flip(p=0.3),\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=(-0.0625, 0.0625), \n",
    "        scale_limit=0, #no scale\n",
    "        rotate_limit=(-90, 90), \n",
    "        p=0.5\n",
    "    ),\n",
    "    AP.ToTensorV2(transpose_mask=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    AP.ToTensorV2(transpose_mask=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "all_dates = GeoEOModule(\n",
    "    transform = transforms,\n",
    "    test_transform = test_transform,\n",
    "    target_mask_name = '2groups',\n",
    "    train_eopatches_dir = eopatches_dir, \n",
    "    test_eopatches_dir = eopatches_dir_test, \n",
    "    predict_eopatches_dir = eopatches_dir_test, \n",
    "    train_eopatches_ids = [x for x in range(num_ids_train)], \n",
    "    test_eopatches_ids = [x for x in range(num_ids_test)],\n",
    "    predict_eopatches_ids = [x for x in range(num_ids_test)], \n",
    "    train_date_range = ['2018-01-01', '2018-12-31'],\n",
    "    test_date_range = ['2018-01-01', '2018-12-31'],\n",
    "    predict_date_range = ['2018-01-01', '2018-12-31'], #['2018-01-01', '2018-12-31'],\n",
    "    batch_size = 128,\n",
    "    num_workers = 16,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from module import SegModule\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB__SERVICE_WAIT\"] = \"500\"\n",
    "\n",
    "wandb_logger = WandbLogger(project='dl-pipeline-sakhalin-2groups', log_model=True)\n",
    "print(f'ü§ñ: Look at {wandb.run.url}')\n",
    "\n",
    "lr_monitor_callback = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=f'/beegfs/home/alina.smolina/DL-pipeline/weights/group-2groups-sakhalin/{wandb.run.name}/',\n",
    "    filename='{epoch}-{val_loss:.5f}', \n",
    "    monitor='val/mean_acc',\n",
    "    mode='max',\n",
    "    save_top_k=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dddfca-3ee6-4c7d-b569-dafef7a4cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=500, \n",
    "    benchmark=True, \n",
    "    check_val_every_n_epoch=10, \n",
    "    logger=wandb_logger, \n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        lr_monitor_callback,\n",
    "            ],\n",
    ")\n",
    "\n",
    "model = SegModule(\n",
    "    optimizer='Adam', \n",
    "    scheduler='StepLR',\n",
    "    step_size=100,\n",
    "    gamma=0.8,\n",
    "    lr=6e-3,\n",
    "    in_channels=10,\n",
    "    ignore_index=255,\n",
    "    min_channels = 16,\n",
    "    max_channels = 1024,\n",
    "    num_down_blocks = 6,\n",
    "    num_classes=2, \n",
    "    class_labels_dict={\n",
    "        0: '–ª–∏—Å—Ç–≤–µ–Ω–Ω—ã–µ', \n",
    "        1: '—Ö–≤–æ–π–Ω—ã–µ', \n",
    "        255:'–Ω–µ—Ç_–¥–∞–Ω–Ω—ã—Ö'\n",
    "        },\n",
    "    labels_to_calc_metric=['–ª–∏—Å—Ç–≤–µ–Ω–Ω—ã–µ', '—Ö–≤–æ–π–Ω—ã–µ'],\n",
    "    possible_classes=[0, 1]\n",
    ")\n",
    "\n",
    "trainer.fit(model, all_dates) \n",
    "\n",
    "trainer.test(model, all_dates)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
